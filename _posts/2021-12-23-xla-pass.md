---
layout: post
title: XLA Pass功能分析
date: 2021-12-23
comments: true
categories: [ "TensorFlow", "XLA" ]
---

- [1. XLA Pass概述](#1-xla-pass概述)
- [2. XLA重点Pass类功能分析](#2-xla重点pass类功能分析)
  - [2.1 GpuConvAlgorithmPicker](#21-gpuconvalgorithmpicker)
  - [2.2 BatchNormExpander](#22-batchnormexpander)
  - [2.3 GpuInstructionFusion](#23-gpuinstructionfusion)
  - [2.4 FusionMerger](#24-fusionmerger)
  - [2.5 GpuMultiOutputFusion](#25-gpumultioutputfusion)
- [3. 附录：`TensorFlow + XLA` VS `Paddle + CINN`](#3-附录tensorflow--xla-vs-paddle--cinn)

## 1. XLA Pass概述

<center>
    <img src="/images/posts/xla/pass_uml.svg" width="100%" alt="XLA Pass UML" title="XLA Pass 类UML图"/>
    <p>图 1. XLA Pass 类UML图</p>
</center>

分析`GpuCompiler::OptimizeHloModule`的调用过程，总结在GPU设备上XLA所使用的Pass类型及其之间的关系如图1所示。由图1可知，GPU上所使用的优化Pass基本是`HloModulePass`和`OpExpanderPass`的子类。去除四个用于保证HLO到LLVM IR之间转换正确性的Pass，在GPU上XLA使用的优化Pass多达75个。

HloPassInterface位于XLA HLO Pass继承关系的最顶层（即所有Pass类的公共基类），它主要定义了*Run*和*RunOnModuleGroup*两个纯虚函数，由其衍生出`HloPassPipeline`、`HloModulePass`和`HloModuleGroupPass`三个子类。XLA HLO Pass优化过程可由多个pipeline构成，每个pipeline即为`HloPassPipeline`的一个对象。GPU上的XLA Pass优化即被分为**spmd-partitioner**[^1]、**spmd-simplify**、**optimization**、**simplification**、**collective-optimizations**、**conv-canonicalization**、**layout-assignment**、**nvptx post-layout-assignment part 1**、**post-layout-assignment**、**nvptx post-layout-assignment part 2**、**fusion**、**horizontal-fusion**、**post-fusion-optimization**以及**GPU-ir-emit-prepare**等14个pipeline。基本上所有的优化Pass均直接或间接继承自`HloModulePass`类。`OpExpanderPass`是`HloModulePass`的一个子类，由其再派生出十数个子类，主要用于各类算子的展开。`HloModuleGroupPass`类在XLA中基本没有被使用到。`HloPassFix`更类似一个修饰类，其模板参数会作为该类的父类，模板参数类被修饰后只会运行固定的迭代次数。

## 2. XLA重点Pass类功能分析
基于TensorFlow 官方ResNet50 benchmark程序[resnet50_graph_test](https://github.com/tensorflow/tensorflow/blob/87462bfac761435a46641ff2f10ad0b6e5414a4b/tensorflow/python/eager/benchmarks/resnet50/resnet50_graph_test.py#L98)，我们在A100-40GB单卡上执行ResNet50的训练过程，以此来分析XLA HLO Pass的优化效果。执行命令中使用了`TF_XLA_FLAGS=--tf_xla_auto_jit=2`来开启XLA加速。
<center>
    <img src="/images/posts/xla/pass_call.svg" width="100%" alt="xla pass call" title="ResNet50模型训练中使用到的Pass调用顺序"/>
    <p>图 2. ResNet50模型训练中使用到的Pass调用顺序</p>
</center>

<center>
    <img src="/images/posts/xla/xla_pass_count.png" width="100%" alt="xla pass count" title="ResNet50模型训练中使用到的Pass及其调用次数"/>
    <p>图 3. ResNet50模型训练中使用到的Pass及其调用次数</p>
</center>

如图2和图3所示，TensorFlow进行ResNet50模型训练并开启XLA时总共触发了72个HLO优化Pass，并且某些Pass的调用次数要大于1，故而Pass调用总次数为97。举例来说，`AlgebraicSimplifier`的调用次数为5，其在`simplification pipeline`、`collective-optimizations pipeline`、`post-fusion optimization pipeline`、`post-layout-assignment pipeline`以及`conv-canonicalization pipeline`等5个pipeline中均被调用一次。图2给出的Pass间连接关系诠释了这些Pass的前后调用依赖。

<center>
    <img src="/images/posts/xla/xla_dis_pass_kernel_time.png" width="100%" alt="xla pass time" title="ResNet50模型训练中使用到的Pass效果分析（batch size=256时的GPU Kernels总运行时间）"/>
    <p>图 4. ResNet50模型训练中使用到的Pass效果分析（batch size=256时的GPU Kernels总运行时间）</p>
</center>

<center>
    <img src="/images/posts/xla/xla_dis_pass_total_time.png" width="100%" alt="xla pass time" title="ResNet50模型训练中使用到的Pass效果分析（batch size=256时的GPU操作总耗时）"/>
    <p>图 5. ResNet50模型训练中使用到的Pass效果分析（batch size=256时的GPU操作总耗时）</p>
</center>

在A100-40GB单卡上执行resnet50_graph_test程序中的`benchmark_graph_train`部分（batch size = 256），得到的性能数据在850 ~ 910 examples/sec之间浮动，这不利于后续对单个Pass所起效果的分析。再三考虑之后，我们选择使用**nsight system**工具获取GPU Kernels的总运行时间以及GPU Kernels执行加显存操作的总耗时来作为性能指标。图4和图5是我们对72个Pass逐一禁用得到的GPU Kernels总运行时间和GPU上所有操作总耗时的对比分析柱状图。图4和图5中的横坐标是以毫秒为单位的耗时，纵坐标中每一个标签均以`DIS_`开头，其为`Disable`的缩写。`DIS_None`是基线数据，表示不禁用任何Pass， `DIS_XX`表示禁用某一个Pass。

*注意：因禁用`GpuConvPaddingLegalization`、`GpuLayoutAssignment`和`ReductionDimensionGrouper`三个Pass中的任意一个均会导致程序运行出现coredump等严重错误，因此无法测量出禁用这三个Pass时的性能数据。*

<center>
    <img src="/images/posts/xla/xla_dis_pass_kernel_speedup.png" width="100%" alt="xla pass speedup" title="ResNet50模型训练中使用到的Pass效果分析（高亮关闭后GPU Kernels性能下降1%的Pass）"/>
    <p>图 6. ResNet50模型训练中使用到的Pass效果分析（高亮关闭后GPU Kernels性能下降1%的Pass）</p>
</center>

<center>
    <img src="/images/posts/xla/xla_dis_pass_total_speedup.png" width="100%" alt="xla pass speedup" title="ResNet50模型训练中使用到的Pass效果分析（高亮关闭后GPU操作总性能下降1%的Pass）"/>
    <p>图 7. ResNet50模型训练中使用到的Pass效果分析（高亮关闭后GPU操作总性能下降1%的Pass）</p>
</center>

对图4和图5中的数据分别做归一化处理后（除以基线数据耗时），可得到图6和图7。图6和图7中对禁用后性能下降超过1%的Pass做了红色高亮处理。分析图6中的红色高亮部分，可得禁用**BatchNormExpander**、**FusionMerger**、**GpuConvAlgorithmPicker**、**GpuInstructionFusion**、**GpuMultiOutputFusion**等5个Pass后，GPU Kernel总执行耗时增加比较明显。分析图7中的红色高亮部分，可得禁用**BatchNormExpander**、**ConditionalCanonicalizer**、**FusionBitcastLift**、**FusionMerger**、**GemmRewriter**、**GpuConvAlgorithmPicker**、**GpuHorizontalLoopFusion**、**GpuInstructionFusion**、**GpuMultiOutputFusion**等9个Pass后，GPU Kernels执行加显存操作的总耗时增加比较明显。

* **GPU Kernels总执行耗时影响程度(数值越低影响越大)**：<br> GpuConvAlgorithmPicker(0.430) > GpuInstructionFusion(0.495) > BatchNormExpander(0.799) > FusionMerger(0.902) > GpuMultiOutputFusion(0.927)
* **GPU Kernels执行加显存操作的总耗时影响程度(数值越低影响越大)**: GpuConvAlgorithmPicker(0.476) > GpuInstructionFusion(0.531) > BatchNormExpander(0.829) > FusionMerger (0.935) > GpuMultiOutputFusion(0.982)  > SortSimplifier(0.990)

因为GPU Kernels执行和显存操作(D2H/H2D/D2D/memset)可能存在并行发生的情况，所以GPU Kernels执行加显存操作的总耗时并不能正确表示训练性能。因此，这里我们主要还是以GPU Kernels总执行耗时作为性能对比指标。根据上述各个XLA HLO Pass对ResNet50模型训练性能的影响程度，下面我们重点分析GpuConvAlgorithmPicker、GpuInstructionFusion、BatchNormExpander、FusionMerger和GpuMultiOutputFusion等五个Pass。

### 2.1 GpuConvAlgorithmPicker

`GpuConvAlgorithmPicker`类主要用于将HLO的CustomCalls修改为cudnn卷积，并为每一个卷积操作选择最佳算法以及为CustomCalls添加x显式的暂存空间(scratch space[^2])。它的类定义如图8所示，Run方法的作用对象是HloModule，其会遍历HloModule的每个非融合类型的Computations，进而调用私有方法RunOnComputation对选定的HloComputation进行处理。RunOnComputation方法会遍历其内部的所有Instructions，并对每一条CustomCall卷积指令进行RunOnInstruction方法的调用处理。RunOnInstruction方法会调用PickBestAlgorithm方法来为指定的CustomCall卷积指令选择最佳算法。

<center>
    <img src="/images/posts/xla/gpu_conv_algorithm_picker.svg" width="100%" alt="GpuConvAlgorithmPicker" title="GpuConvAlgorithmPicker相关类UML图"/>
    <p>图 8. GpuConvAlgorithmPicker相关类UML图</p>
</center>

### 2.2 BatchNormExpander
<center>
    <img src="/images/posts/xla/batch_norm_expander.svg" width="100%" alt="BatchNormExpander" title="BatchNormExpander相关类UML图"/>
    <p>图 9. BatchNormExpander相关类UML图</p>
</center>

### 2.3 GpuInstructionFusion

### 2.4 FusionMerger

### 2.5 GpuMultiOutputFusion

<!-- ### 2.6 AlgebraicSimplifier

AlgebraicSimplifierl类在若干个优化pipeline中均有使用，它主要提了一些代数化简功能。
<center>
    <img src="/images/posts/xla/algebraic_simplifier.svg" width="100%" alt="AlgebraicSimplifier" title="AlgebraicSimplifier相关类UML图"/>
    <p>图 8. AlgebraicSimplifier相关类UML图</p>
</center>

如图7所示，构造`AlgebraicSimplifier`对象时需要传入一个`AlgebraicSimplifierOptions`对象，其定义了一系列的代数化简选项，如与`layout`、`dot`、`conv`、`scalar multiply reduction`、`padding`及`transpose`相关选项。`AlgebraicSimplifier`类重写了父类的`Run`方法，运行`Run`方法时会自动创建一个`AlgebraicSimplifierVisitor`对象*visitor*，之后使用*visitor*对`HloModule`中的每个`HloComputation`进行处理。每个`HloComputation`对象会使用传入的`AlgebraicSimplifierVisitor`对象从`Root HloInstruction`开始使用后序DFS遍历方式处理该computation中的每一条指令。`AlgebraicSimplifierVisitor`对象根据每条`HloInstruction`对象的`HloOpcode`值调用相应的`HandleXXX`方法处理该指令。

`AlgebraicSimplifierVisitor`类会对`Abs`、`Add`、`And`、`Bitcast`、`BitcastConvert`、`Broadcast`、`Compare`、`Concatenate`、`Constant`、`Copy`、`Convert`、`Complex`、`Real`、`Imag`、`Iota`、`Convolution`、`Divide`、`Dot`、`Gather`、`GetTupleElement`、`Log`、`Maximum`、`Minimum`、`Clamp`、`Multiply`、`Negate`、`Not`、`Or`、`Pad`、`Power`、`Remainder`、`Reshape`、`Reduce`、`ReduceWindow`、`Reverse`、`Rsqrt`、`Slice`、`Sqrt`、`DynamicSlice`、`DynamicUpdateSlice`、`Scatter`、`Select`、`Sort`、`Transpose`、`Subtract`和`Map`等46个算子进行代数化简处理。

* `HandleAbs`：当`Abs`的操作数为正时，进行`Abs(A) => A`的简化。
* `HandleAdd`: 对`Add`进行的简化操作如下：
  - `A + 0 => A`
  - `0 + A => A`
  - 将常数放在加法的右边，方便后续重分配规则的简化，即`Const + A => A + Const`
  - 对加法的操作数进行重新分配，方便后续的常量折叠，即`(A + C1) + C2 => A + (C1 + C2)` -->

## 3. 附录：`TensorFlow + XLA` VS `Paddle + CINN`

<center> 表 1. TensorFlow + XLA 和 Paddle + CINN在ResNet50模型上的训练性能对比</center>

| Framework        | GPU Kernel Time(ms) | GPU Kernel+Mem Time(ms) | Samples/sec |
|------------------|---------------------|-------------------------|-------------|
| TensorFlow + XLA | 257                 | 290~310                 | 845 ~ 905   |
| Paddle + CINN    | 296                 | 310                     | 862         |


[^1]: SPMD (Single-Program-Multiple-Data) 是最常用的分布式模式，即数据并行。
[^2]: In general, a scratch space is a temporary location in memory that allows for something to be saved.